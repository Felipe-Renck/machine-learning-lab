{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Template <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this template, please use the [file tree](./) to duplicate this notebook and move it to the folder of your repository. The following sections contain only exemplary content, please adapt and change based on your experiment implementation.\n",
    "\n",
    "**In this notebook:**\n",
    "\n",
    "* Describe your notbeook here in a few bullet points, e.g.:\n",
    "* Method xyz on dataset abc --> Key insight: xyz works pretty well\n",
    "* Modification zyx --> Dead end\n",
    "\n",
    "**Todo:**\n",
    "\n",
    "* List all todos that are related to this notebook here, e.g.:\n",
    "* Apply xyz to another dataset\n",
    "\n",
    "This could be some more general information on method xyz (e.g. a link to a paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "Install, load, and initialize all required dependencies for this experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Dependencies\n",
    "- _Please use a Python 3 kernel for the notebook_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-29T21:35:07.570589Z",
     "start_time": "2018-10-29T21:33:28.856649Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install any packages that are not included in the workspace.\n",
    "# It should be possible to run the notebook independent of anything else. \n",
    "# If dependency cannot be installed via pip, either:\n",
    "# - download & install it via %%bash\n",
    "# - atleast mention those dependecies in this section\n",
    "import sys\n",
    "\n",
    "# sys.executable points to the python that is running in your kernel \n",
    "!{sys.executable} -m pip install -q sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T18:45:12.799022Z",
     "start_time": "2018-02-26T18:45:12.784137Z"
    }
   },
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T09:40:02.472489Z",
     "start_time": "2020-08-12T09:40:01.241583Z"
    }
   },
   "outputs": [],
   "source": [
    "# System libraries\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import logging, os, sys\n",
    "\n",
    "# Enable logging\n",
    "logging.basicConfig(format='[%(levelname)s] %(message)s', level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "# Re-import packages if they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Intialize tqdm to always use the notebook progress bar\n",
    "import tqdm\n",
    "tqdm.tqdm = tqdm.tqdm_notebook\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "%config InlineBackend.figure_format='retina'  # adapt plots for retina displays\n",
    "\n",
    "# Lab libraries\n",
    "from lab_client import Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T09:40:08.622990Z",
     "start_time": "2020-08-12T09:40:06.901756Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize environment\n",
    "env = Environment(project=\"test\",  # Lab project you want to work on\n",
    "                  # Only required in stand-alone workspace deployments\n",
    "                  # lab_endpoint=\"LAB_ENDPOINT\", # Lab endpoint url: e.g. http://10.2.3.45:8091\n",
    "                  # lab_api_token=\"LAB_API_TOKEN\"\n",
    "                 ) \n",
    "\n",
    "# Initialize experiment\n",
    "exp = env.create_experiment('Experiment Template')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Download, explore, and prepare all required data for the experiment in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T16:41:53.434064Z",
     "start_time": "2018-02-26T16:41:53.431218Z"
    }
   },
   "source": [
    "### Download & Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from remote storage of ML Lab only if it does not exist locally\n",
    "dataset_path = env.get_file('YOUR_DATASET_KEY')\n",
    "\n",
    "# Read data into basic datastructures (e.g. dict, list, dataframe). E.g. csv via pandas:\n",
    "# For example: read csv via pandas\n",
    "df = pd.read_csv(dataset_path, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do data exploration, statistics visualization (pandas profiling, qgrid, facets...)\n",
    "# For example: pandas profiling\n",
    "import pandas_profiling\n",
    "pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure data dataset configuration\n",
    "dataset_config = {\n",
    "    'test_size':0.20\n",
    "}\n",
    "\n",
    "# Add dataset configuration to experiment parameters\n",
    "exp.log_params(dataset_config)\n",
    "\n",
    "# Data preprocessing\n",
    "# <YOUR DATA PREPROCESSING CODE HERE>\n",
    "\n",
    "# Split the dataset into train (80%), and test (20%) based on dataset configuration\n",
    "train_df, test_df = np.split(df.sample(frac=1, random_state=1), [int(1-dataset_config['test_size']*len(df))])\n",
    "\n",
    "print('Train corpus size: '+str(len(train_df)))\n",
    "print('Test corpus size: '+str(len(test_df)))\n",
    "\n",
    "# add dataframes to experiment (will be logged and accesible within the experiment)\n",
    "exp.add_artifact(\"train_data\", train_df)\n",
    "exp.add_artifact(\"test_data\", test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "Implementation, configuration, and evaluation of the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T16:57:25.500621Z",
     "start_time": "2018-02-26T16:57:25.481298Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function with the required code to run the experiment (e.g. train model)\n",
    "def train(exp, params, artifacts):\n",
    "    # the parameters will be automatically provided when running via run_exp but are not required\n",
    "    # exp (= Experiment instance)\n",
    "    # params (= parameter dictonary) \n",
    "    # artifacts (= dictionary of added artifacts)\n",
    "    \n",
    "    # Get artifacts for the experiment run\n",
    "    train_df = artifacts[\"train_data\"]\n",
    "    test_df = artifacts[\"test_data\"]\n",
    "    \n",
    "    # Experiment Implementation\n",
    "    # <YOUR EXPERIMENT CODE HERE>\n",
    "    # model_instance = <THE TRAINED MODEL INSTANCE>\n",
    "    \n",
    "    # Use experiment to get a path to store the trained model within the dedicated experiment folder\n",
    "    model_path = exp.create_file_path(\"trained.model\")\n",
    "    # <SAVE YOUR ARTIFACTS HERE>\n",
    "    \n",
    "    # Add trained model instance to experiment, so it can accessed after the experiment run is finished\n",
    "    # exp.add_artifact(\"trained_model\", model_instance)\n",
    "    \n",
    "    # Evaluate trained model\n",
    "    score = 1\n",
    "    \n",
    "    # log a metric to the current experiment\n",
    "    # <LOG YOUR METRICS HERE>\n",
    "    exp.log_metric(\"accuracy\", score)\n",
    "    \n",
    "    # optional: return the most descriptive metric for the experiment (main objective of the experiment)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter configuration for experiment run\n",
    "params = {\n",
    "    'param': 0, # value should be string, int or float\n",
    "}\n",
    "\n",
    "# Run experiment and sync all metadata\n",
    "exp.run_exp(train, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T18:35:48.172911Z",
     "start_time": "2018-02-26T18:35:48.154756Z"
    }
   },
   "source": [
    "### Optional: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do evaluation, e.g. visualisations  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model\n",
    "Wrap the model with the Unified Model API and upload it to the remote storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Unified Model\n",
    "You can find information on how to create a self-contained executable model file in the [unified model library](https://github.com/SAP/machine-learning-lab/tree/master/libraries/unified-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T09:22:04.260584Z",
     "start_time": "2018-10-30T09:22:04.232830Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create unified model instance here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Unified Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.upload_file(model_path, data_type=\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Information\n",
    "This section provides some additional information and guidelines for building high-quality reusable notebooks. **Please remove this section** for your experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T18:44:08.786233Z",
     "start_time": "2018-02-26T18:44:08.759395Z"
    }
   },
   "source": [
    "- All cells should be executable in order (with run all and restart & run all).\n",
    "- Every notebook should be self-contained and executable without any prior knowledge. \n",
    "- Frequently rewrite each cell logic into functions. These functions can be moved to separate `.py` files on regular intervals. Your notebook run should be mainly function calls. This would prevent your notebook from becoming a giant pudding of several global variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naming Conventions for Headings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: First Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute either this..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Second Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...or this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this for an optional feature."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "840px",
    "width": "569px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
